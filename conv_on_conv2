from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

def cnn_model_fn(features, labels, mode):
		input_layer = tf.reshape(features["x"], [-1, 28, 28, 1])

		conv1 = tf.layers.conv2d(
			inputs= input_layer,
			filters = 32,
			kernel_size = 3,
			padding = "same",
			activation = tf.nn.relu
			)

		conv_on_conv1 = tf.layers.conv2d(
			inputs = conv1,
			filters = 32,
			kernel_size = 3,
			padding = 'same',
			activation = tf.nn.relu)

		inception1 = tf.layers.conv2d(
			inputs = conv1,
			filters = 64,
			kernel_size = 1,
			padding = 'same',
			activation = tf.nn.relu)

		maxpool1 = tf.layers.max_pooling2d(inputs = inception1, pool_size = 2, strides = 2)

		conv2 = tf.layers.conv2d(
			inputs = maxpool1,
			filters = 64,
			kernel_size = 3,
			padding = "same",
			activation = tf.nn.relu
			)

		conv_on_conv2 = tf.layers.conv2d(
			inputs = conv2,
			filters = 64,
			kernel_size = 3,
			padding = 'same',
			activation = tf.nn.relu)

		inception2 = tf.layers.conv2d(
			inputs = conv1,
			filters = 128,
			kernel_size = 1,
			padding = 'same',
			activation = tf.nn.relu)

		#some work can be done here by adding filters and shrinking the size of the kernels

		maxpool2 = tf.layers.max_pooling2d(inputs = conv_on_conv2, pool_size = 2, strides = 2)

		conv3 = tf.layers.conv2d(
			inputs = maxpool2,
			filters = 128,
			kernel_size = 3,
			padding = 'same',
			activation = tf.nn.relu
			)

		conv_on_conv3 = tf.layers.conv2d(
			inputs = conv3,
			filters = 128,
			kernel_size = 3,
			padding = 'same',
			activation = tf.nn.relu)

		maxpool3 = tf.layers.max_pooling2d(inputs = conv_on_conv3, pool_size = 2, strides = 2, padding = 'same')

		conv4 = tf.layers.conv2d(
			inputs = maxpool3,
			filters = 256,
			kernel_size = 3,
			padding = 'same',
			activation = tf.nn.relu)

		conv_on_conv4 = tf.layers.conv2d(
			inputs = conv4,
			filters = 256,
			kernel_size = 3,
			padding = 'same',
			activation = tf.nn.relu)

		maxpool4 = tf.layers.max_pooling2d(inputs = conv_on_conv4, pool_size = 2,strides = 2)

		maxpool5_flat = tf.reshape(maxpool4, [-1, 2 * 2 * 256])

		dense = tf.layers.dense(inputs = maxpool5_flat, units = 1024, activation = tf.nn.relu)

		dropout = tf.layers.dropout(inputs = dense, rate = 0.5, training=mode == tf.estimator.ModeKeys.TRAIN)

		logits = tf.layers.dense(inputs = dropout, units = 10)

		predictions = {
		"classes" : tf.argmax(input = logits, axis = 1),
		"probablilities" : tf.nn.softmax(logits, name = "softmax_tensor")
		}

		if mode == tf.estimator.ModeKeys.PREDICT:
			return tf.estimator.EstimatorSpec(mode = mode, predictions = predictions)

		loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, logits = logits)

		if mode == tf.estimator.ModeKeys.TRAIN:
			global_step = tf.train.get_global_step()
			optimizer = tf.train.AdamOptimizer(
				learning_rate = 0.001,
				beta1 = 0.9,
				beta2 = 0.999,
				epsilon = 1e-08,
				)
			train_op = optimizer.minimize(
				loss = loss,
				global_step = tf.train.get_global_step()
				)
			return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_op)

		eval_metric_ops = {
			"accuracy": tf.metrics.accuracy(
				labels = labels, predictions = predictions["classes"])
		}
		return tf.estimator.EstimatorSpec(mode = mode, loss = loss, eval_metric_ops = eval_metric_ops)

def main(unused_argv):
	mnist = tf.contrib.learn.datasets.load_dataset("mnist")
	train_data = mnist.train.images
	train_labels = np.asarray(mnist.train.labels, dtype = np.int32)
	eval_data = mnist.test.images
	eval_labels = np.asarray(mnist.test.labels, dtype = np.int32)

	mnist_classifier = tf.estimator.Estimator(model_fn = cnn_model_fn, model_dir = "/tmp/mnist_convnet_convonconv4")

	tensors_to_log = {"probablilities" : "softmax_tensor"}
	logging_hook = tf.train.LoggingTensorHook(tensors = tensors_to_log, every_n_iter = 50)

	train_input_fn = tf.estimator.inputs.numpy_input_fn(
		x = {"x": train_data},
		y = train_labels,
		batch_size = 128,
		num_epochs = None,
		shuffle = True
		)

	mnist_classifier.train(
		input_fn = train_input_fn,
		steps = 30000,
		hooks = [logging_hook]
		)

	eval_input_fn = tf.estimator.inputs.numpy_input_fn(
		x = {"x" : eval_data,},
		y = eval_labels,
		num_epochs = 1,
		shuffle = False)

	eval_results = mnist_classifier.evaluate(input_fn = eval_input_fn)
	print(eval_results)

if __name__ == '__main__':
	tf.app.run()
